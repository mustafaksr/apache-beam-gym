{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551eca25-8018-43cd-bbcb-58789570d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nautilus --browser /media/desktop/01D7E2330EB2B040/google-cloud-ml/training-data-analyst-master/quests/dataflow_python/8b_Stream_Testing_Pipeline/solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb67c9ed-2bcf-4c65-bb36-b8c8b5be499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lab_10_taxi_streaming_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab_10_taxi_streaming_pipeline.py\n",
    "import json\n",
    "import typing\n",
    "import logging\n",
    "import apache_beam as beam\n",
    "from apache_beam.transforms.trigger import AccumulationMode, AfterCount, AfterWatermark\n",
    "from apache_beam.transforms.combiners import CountCombineFn\n",
    "import argparse\n",
    "\n",
    "class TaxiRide(typing.NamedTuple):\n",
    "    ride_id: str\n",
    "    point_idx: int\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    timestamp: str\n",
    "    meter_reading: float\n",
    "    meter_increment: float\n",
    "    ride_status: str\n",
    "    passenger_count: int\n",
    "\n",
    "beam.coders.registry.register_coder(TaxiRide, beam.coders.RowCoder)\n",
    "\n",
    "class JsonToTaxiRide(beam.DoFn):\n",
    "\n",
    "    def process(self, line):\n",
    "        row = json.loads(line)\n",
    "        yield TaxiRide(**row)\n",
    "\n",
    "class ConvertCountToDict(beam.DoFn):\n",
    "\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        window_start = window.start.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        output = {\"taxi_rides\" : element, \"timestamp\": window_start}\n",
    "        yield output\n",
    "\n",
    "\n",
    "class TaxiCountTransform(beam.PTransform):\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "        \n",
    "        output = (pcoll\n",
    "                    | \"ParseJson\" >> beam.ParDo(JsonToTaxiRide())\n",
    "                    | \"FilterForPickups\" >> beam.Filter(lambda x : x.ride_status == 'pickup')\n",
    "                    | \"WindowByMinute\" >> beam.WindowInto(beam.window.FixedWindows(60),\n",
    "                                              trigger=AfterWatermark(late=AfterCount(1)),\n",
    "                                              allowed_lateness=60,\n",
    "                                              accumulation_mode=AccumulationMode.ACCUMULATING)\n",
    "                    | \"CountPerMinute\" >> beam.CombineGlobally(CountCombineFn()).without_defaults()\n",
    "                 )\n",
    "\n",
    "        return output\n",
    "\n",
    "def run():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Load from Json from Pub/Sub into BigQuery')\n",
    "\n",
    "    parser.add_argument('--table_name', required=True, help='Output BQ table')\n",
    "\n",
    "    opts = parser.parse_args()\n",
    "\n",
    "    table_name = opts['table_name']\n",
    "\n",
    "    table_schema = {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"name\": \"taxi_rides\",\n",
    "                \"type\": \"INTEGER\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"timestamp\",\n",
    "                \"type\": \"STRING\"\n",
    "            },\n",
    "\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    p = beam.Pipeline()\n",
    "\n",
    "    (p | \"ReadFromPubSub\" >> beam.io.ReadFromPubSub(topic=\"projects/pubsub-public-data/topics/taxirides-realtime\") \n",
    "       | \"TaxiPickupCount\" >> TaxiCountTransform()\n",
    "       | \"ConvertToDict\" >> beam.ParDo(ConvertCountToDict())\n",
    "       | 'WriteAggToBQ' >> beam.io.WriteToBigQuery(\n",
    "                table_name,\n",
    "                schema=table_schema,\n",
    "                create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND\n",
    "                )\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efd12d1-3c42-4b09-878e-de2b8b927ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab_10_taxi_streaming_pipeline_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab_10_taxi_streaming_pipeline_test.py\n",
    "import logging\n",
    "import json\n",
    "import unittest\n",
    "import sys\n",
    "\n",
    "import apache_beam as beam\n",
    "\n",
    "from lab_10_taxi_streaming_pipeline import *\n",
    "from apache_beam.testing.test_pipeline import TestPipeline\n",
    "from apache_beam.testing.util import BeamAssertException\n",
    "from apache_beam.testing.util import assert_that, equal_to_per_window\n",
    "from apache_beam.testing.test_stream import TestStream\n",
    "from apache_beam.transforms.window import TimestampedValue, IntervalWindow\n",
    "from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions\n",
    "\n",
    "def main(out = sys.stderr, verbosity = 2):\n",
    "    loader = unittest.TestLoader()\n",
    "  \n",
    "    suite = loader.loadTestsFromModule(sys.modules[__name__])\n",
    "    unittest.TextTestRunner(out, verbosity = verbosity).run(suite)\n",
    "\n",
    "\n",
    "class TaxiWindowingTest(unittest.TestCase):\n",
    "\n",
    "    def test_windowing_behavior(self):\n",
    "\n",
    "        options = PipelineOptions()\n",
    "        options.view_as(StandardOptions).streaming = True\n",
    "\n",
    "        with TestPipeline(options=options) as p:\n",
    "\n",
    "            base_json_pickup = \"{\\\"ride_id\\\":\\\"x\\\",\\\"point_idx\\\":1,\\\"latitude\\\":0.0,\\\"longitude\\\":0.0,\" \\\n",
    "                         \"\\\"timestamp\\\":\\\"00:00:00\\\",\\\"meter_reading\\\":1.0,\\\"meter_increment\\\":0.1,\" \\\n",
    "                         \"\\\"ride_status\\\":\\\"pickup\\\",\\\"passenger_count\\\":1}\" \n",
    "\n",
    "            base_json_enroute = \"{\\\"ride_id\\\":\\\"x\\\",\\\"point_idx\\\":1,\\\"latitude\\\":0.0,\\\"longitude\\\":0.0,\" \\\n",
    "                         \"\\\"timestamp\\\":\\\"00:00:00\\\",\\\"meter_reading\\\":1.0,\\\"meter_increment\\\":0.1,\" \\\n",
    "                         \"\\\"ride_status\\\":\\\"pickup\\\",\\\"passenger_count\\\":1}\" \n",
    "            \n",
    "\n",
    "            test_stream = TestStream().advance_watermark_to(0).add_elements([\n",
    "                TimestampedValue(base_json_pickup, 0),\n",
    "                TimestampedValue(base_json_pickup, 0),\n",
    "                TimestampedValue(base_json_enroute, 0),\n",
    "                TimestampedValue(base_json_pickup, 60)\n",
    "            ]).advance_watermark_to(60).advance_processing_time(60).add_elements([\n",
    "                TimestampedValue(base_json_pickup, 120)\n",
    "            ]).advance_watermark_to_infinity()\n",
    "\n",
    "            taxi_counts = (p | test_stream\n",
    "                             | TaxiCountTransform()\n",
    "                          )\n",
    "\n",
    "            EXPECTED_WINDOW_COUNTS = {IntervalWindow(0,60): [3],\n",
    "                                      IntervalWindow(60,120): [1],\n",
    "                                      IntervalWindow(120,180): [1]}\n",
    "\n",
    "            assert_that(taxi_counts, equal_to_per_window(EXPECTED_WINDOW_COUNTS),\n",
    "                        reify_windows=True)\n",
    "\n",
    "class TaxiLateDataTest(unittest.TestCase):\n",
    "\n",
    "        def test_late_data_behavior(self):\n",
    "\n",
    "            options = PipelineOptions()\n",
    "            options.view_as(StandardOptions).streaming = True\n",
    "\n",
    "            with TestPipeline(options=options) as p:\n",
    "\n",
    "                base_json_pickup = \"{\\\"ride_id\\\":\\\"x\\\",\\\"point_idx\\\":1,\\\"latitude\\\":0.0,\\\"longitude\\\":0.0,\" \\\n",
    "                            \"\\\"timestamp\\\":\\\"00:00:00\\\",\\\"meter_reading\\\":1.0,\\\"meter_increment\\\":0.1,\" \\\n",
    "                            \"\\\"ride_status\\\":\\\"pickup\\\",\\\"passenger_count\\\":1}\" \n",
    "\n",
    "                test_stream = TestStream().advance_watermark_to(0).add_elements([\n",
    "                    TimestampedValue(base_json_pickup, 0),\n",
    "                    TimestampedValue(base_json_pickup, 0),\n",
    "                ]).advance_watermark_to(60).advance_processing_time(60).add_elements([\n",
    "                    TimestampedValue(base_json_pickup, 0)\n",
    "                ]).advance_watermark_to(300).advance_processing_time(240).add_elements([\n",
    "                    TimestampedValue(base_json_pickup, 0)\n",
    "                ])\n",
    "\n",
    "                EXPECTED_RESULTS = {IntervalWindow(0,60): [2,3]}  #On Time and Late Result\n",
    "\n",
    "                taxi_counts_late = (p | test_stream\n",
    "                                      | TaxiCountTransform()\n",
    "                                   )\n",
    "\n",
    "                assert_that(taxi_counts_late, equal_to_per_window(EXPECTED_RESULTS),\n",
    "                            reify_windows=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open('lab_10_testingout.txt', 'w') as f:\n",
    "        main(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9f4ee-ca1b-42de-bae5-7b4d0b3660c8",
   "metadata": {},
   "source": [
    "```bash\n",
    "PROJECT_ID=$(gcloud config get-value project)\n",
    "export PROJECT_NUMBER=$(gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\")\n",
    "export serviceAccount=\"\"$PROJECT_NUMBER\"-compute@developer.gserviceaccount.com\"\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID --member=\"serviceAccount:${serviceAccount}\" --role=\"roles/dataflow.worker\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ba9f9-4deb-486c-8ea9-b71d30ca2054",
   "metadata": {},
   "source": [
    "terminal\n",
    "```bash\n",
    "conda activate beam\n",
    "cd /path\n",
    "python $workdir/lab_10_taxi_streaming_pipeline_test.py\n",
    "cat lab_10_testingout.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c765f55-f34c-42f7-b6e2-ef19bbb59280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_late_data_behavior (__main__.TaxiLateDataTest) ... ok\n",
      "test_windowing_behavior (__main__.TaxiWindowingTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 2.022s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!cat lab_10_testingout.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f43ac7-bdce-4c29-9e4d-9a6bb97f94ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
