{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891ef2a3-9369-4c95-ba4b-6dc5c707ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting titanic_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile titanic_pipeline.py\n",
    "import json\n",
    "import typing\n",
    "import logging\n",
    "import apache_beam as beam\n",
    "\n",
    "class TitanicRecord(typing.NamedTuple):\n",
    "    survived: int\n",
    "    pclass: int\n",
    "    sex: str\n",
    "    age: float\n",
    "    sibsp: int\n",
    "    parch: int\n",
    "    fare: float\n",
    "    embarked: str\n",
    "    deck: str\n",
    "    \n",
    "\n",
    "beam.coders.registry.register_coder(TitanicRecord, beam.coders.RowCoder)\n",
    "\n",
    "class ConvertCsvToTitanicRecord(beam.DoFn):\n",
    "\n",
    "    def process(self, line):\n",
    "        fields = 'survived,pclass,sex,age,sibsp,parch,fare,embarked,deck'.split(',')\n",
    "        values = line.split(',')\n",
    "        row = dict(zip(fields,values))\n",
    "        for num_field in ('age','fare'):\n",
    "            row[num_field] = float(row[num_field])\n",
    "        for int_field in ('survived','pclass','sibsp','parch'):\n",
    "            row[int_field] = int(row[int_field])\n",
    "        yield TitanicRecord(**row)\n",
    "\n",
    "        \n",
    "class AgeFareMultPclass(beam.DoFn):\n",
    "\n",
    "    def process(self, row):\n",
    "        row_dict = row._asdict()\n",
    "        for field in ('age', 'fare'):\n",
    "            row_dict[field] = row_dict[field] * int(row_dict['pclass'])\n",
    "        yield TitanicRecord(**row_dict)\n",
    "##       \n",
    "\n",
    "##\n",
    "class ConvertToJson(beam.DoFn):\n",
    "\n",
    "    def process(self, row):\n",
    "        line = json.dumps(row._asdict())\n",
    "        yield line\n",
    "\n",
    "class ComputeStatistics(beam.PTransform):\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "    \n",
    "        results = (\n",
    "            pcoll | 'ComputeStatistics' >> beam.GroupBy('embarked')\n",
    "                                                .aggregate_field('age', min, 'min_age')\n",
    "                                                .aggregate_field('age', max, 'max_age')\n",
    "                                                .aggregate_field('age', sum, 'sum_age')\n",
    "                | 'ToJson' >> beam.ParDo(ConvertToJson())\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "\n",
    "class TitanicStats(beam.PTransform):\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "\n",
    "        results = (\n",
    "            pcoll | \"ParseCSV\" >> beam.ParDo(ConvertCsvToTitanicRecord())\n",
    "\n",
    "                  | \"ConvertToF\" >> beam.ParDo(AgeFareMultPclass())\n",
    "                  \n",
    "                  | \"ComputeStats\" >> ComputeStatistics()\n",
    "                  \n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "def run():\n",
    "\n",
    "    p = beam.Pipeline()\n",
    "\n",
    "    (p | 'ReadCSV' >> beam.io.ReadFromText('./titanic.csv')\n",
    "       | 'ComputeStatistics' >> ComputeStatistics()\n",
    "       | 'WriteJson' >> beam.io.WriteToText('./titanic', '.json')\n",
    "    )\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info(\"Building pipeline ...\")\n",
    "\n",
    "    p.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f57880d-421c-48ec-aad0-5c226efb4481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting titanic_pipeline_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile titanic_pipeline_test.py\n",
    "import logging\n",
    "import json\n",
    "import unittest\n",
    "import sys\n",
    "\n",
    "from titanic_pipeline import *\n",
    "from apache_beam.testing.test_pipeline import TestPipeline\n",
    "from apache_beam.testing.util import BeamAssertException\n",
    "from apache_beam.testing.util import assert_that, equal_to\n",
    "\n",
    "def main(out = sys.stderr, verbosity = 2):\n",
    "    loader = unittest.TestLoader()\n",
    "  \n",
    "    suite = loader.loadTestsFromModule(sys.modules[__name__])\n",
    "    unittest.TextTestRunner(out, verbosity = verbosity).run(suite)\n",
    "\n",
    "\n",
    "class ConvertToTitanicRecordTest(unittest.TestCase):\n",
    "\n",
    "    def test_convert_to_csv(self):\n",
    "\n",
    "        with TestPipeline() as p:\n",
    "\n",
    "            LINES = ['0,1,male,46.0,1,0,61.175,S,E']\n",
    "            EXPECTED_OUTPUT = [TitanicRecord(0,1,'male',46.0,1,0,61.175,'S','E')]\n",
    "\n",
    "            input_lines = p | beam.Create(LINES)\n",
    "\n",
    "            output = input_lines | beam.ParDo(ConvertCsvToTitanicRecord())\n",
    "\n",
    "            assert_that(output, equal_to(EXPECTED_OUTPUT))\n",
    "\n",
    "class AgeFareMultPclassTest(unittest.TestCase):\n",
    "\n",
    "    def test_mult_units(self):\n",
    "\n",
    "        with TestPipeline() as p:\n",
    "\n",
    "            RECORDS = [TitanicRecord(0,3,'male',24.0,0,1,247.5208,'C','B'),\n",
    "                       TitanicRecord(0,2,'male',54.0,0,1,77.2875,'S','D')]\n",
    "\n",
    "            EXPECTED_RECORDS = [TitanicRecord(0,3,'male',72.0,0,1,742.5624,'C','B'),\n",
    "                               TitanicRecord(0,2,'male',108.0,0,1,154.575,'S','D')]\n",
    "\n",
    "            input_records = p | beam.Create(RECORDS)\n",
    "\n",
    "            output = input_records | beam.ParDo(AgeFareMultPclass())\n",
    "            \n",
    "            assert_that(output, equal_to(EXPECTED_RECORDS))\n",
    "\n",
    "class ComputeStatsTest(unittest.TestCase):\n",
    "    \n",
    "    def test_compute_statistics(self):\n",
    "\n",
    "        with TestPipeline() as p:\n",
    "\n",
    "            INPUT_RECORDS = [TitanicRecord(0,1,'female',50.0,0,0,28.7125,'C','C'),\n",
    "                             TitanicRecord(1,1,'female',44.0,0,0,27.7208,'C','B'),\n",
    "                             TitanicRecord(1,1,'female',31.0,1,0,113.275,'C','D'),\n",
    "                             TitanicRecord(1,1,'female',58.0,0,1,153.4625,'S','C'),\n",
    "                             TitanicRecord(1,1,'female',35.0,0,0,135.6333,'S','C')]\n",
    "\n",
    "            EXPECTED_STATS = [json.dumps({'embarked': 'C', 'min_age': 31.0, 'max_age': 50.0, 'sum_age': 125.0 }),\n",
    "                              json.dumps({'embarked': 'S', 'min_age': 35.0, 'max_age': 58.0, 'sum_age': 93.0 })]\n",
    "\n",
    "            inputs = p | beam.Create(INPUT_RECORDS)\n",
    "\n",
    "            output = inputs | ComputeStatistics()\n",
    "\n",
    "            assert_that(output, equal_to(EXPECTED_STATS))\n",
    "\n",
    "class TitanicStatsTransformTest(unittest.TestCase):\n",
    "\n",
    "    def test_titanic_stats_transform(self):\n",
    "\n",
    "        with TestPipeline() as p:\n",
    "\n",
    "            INPUT_STRINGS = [\"0,1,female,50.0,0,0,28.7125,C,C\",\n",
    "                             \"1,1,female,44.0,0,0,27.7208,C,B\",\n",
    "                             \"1,1,female,58.0,0,1,153.4625,S,C\"]\n",
    "\n",
    "            EXPECTED_STATS = [json.dumps({'embarked': 'C', 'min_age': 44.0, 'max_age': 50.0, 'sum_age': 94.0 }),\n",
    "                              json.dumps({'embarked': 'S', 'min_age': 58.0, 'max_age': 58.0, 'sum_age': 58.0 })]\n",
    "\n",
    "            inputs = p | beam.Create(INPUT_STRINGS)\n",
    "\n",
    "            output = inputs | TitanicStats()\n",
    "\n",
    "            assert_that(output, equal_to(EXPECTED_STATS))\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with open('testing.txt', 'w') as f:\n",
    "        main(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6605e3d-4370-474c-a873-40eadaa5e05a",
   "metadata": {},
   "source": [
    "terminal\n",
    "```bash\n",
    "conda activate beam\n",
    "cd /path\n",
    "python3 titanic_pipeline_test.py\n",
    "cat testing.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f98cbb-0922-441e-892c-4853720bcc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mult_units (__main__.AgeFareMultPclassTest) ... ok\n",
      "test_compute_statistics (__main__.ComputeStatsTest) ... ok\n",
      "test_convert_to_csv (__main__.ConvertToTitanicRecordTest) ... ok\n",
      "test_titanic_stats_transform (__main__.TitanicStatsTransformTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 3.387s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda activate beam\n",
    "cd /path\n",
    "python3 titanic_pipeline_test.py\n",
    "cat testing.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fe987-98dd-4ed0-84a0-cf56cfaac03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
